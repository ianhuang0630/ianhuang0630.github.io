<!DOCTYPE html>
<html lang="en">

<head>
    <title> Publications </title>
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Libre+Barcode+39+Extended" rel="stylesheet">
    <link rel="stylesheet" type= "text/css" href="styles/style.css">
    <link rel="stylesheet" type= "text/css" href="styles/style_publications.css">
</head>
<body>
    <div class="tabs">
        <a href="index.html" class="tab0">Me</a> |
        <a href="publications.html" class="tab1">Publications</a> | 
        <a href="pet_projects.html" class="tab2">Pet Projects</a> |
        <a href="resume_cv.html" class="tab3">Resume/CV</a> |
        <a href="https://github.com/ianhuang0630" class="tab4">GitHub</a> |
        <a href="contact.html" class="tab5">Contact</a>
    </div>
   
    <div class="centerhead">
        <div class="headers">
            <h1 id="header1">Publications</h1>
            <h2 id="header2">(and works in progress)</h2>
        </div>
    </div> 
    
    <div class="researchpaperlist fade-in">
        <!-- list of publications -->
        <div> 
        <div class="researchpaper">
            <div class="paper-image">
                <img src="assets/pictures/paper4.png" class="paper_pic">
            </div>
            <div class="paper-description">
                <h3 class=tab4> Functionality-driven Object Discovery in Videos</h3> 
                <p>The world needs an AI that can reason about unfamiliar environments, objects, and entities. 
                I designed and developed a model that deduces the taxonomic relationship between seen and 
                unseen objects by observing human interactions with those classes in video data. I introduced 
                object-functionality projection, a novel technique to embed the functionality of objects as a 
                representation of their interactions with others in a latent space. It demonstrated significant 
                improvements upon baselines and prior works (at least a 27% relative increase – or 6% absolute – 
                in cumulative accuracy, and under some conditions, a 4x increase in accuracy).</p>
                <a href="assets/papers/2020CVPR_functionality_driven_object_discovery_in_videos.pdf.pdf" class=tab1>PDF</a>
            </div> 
        </div>
        

        <div class="researchpaper">
            <div class="paper-image">
                <img src="assets/pictures/paper3.png" class="paper_pic">
            </div>
            <div class="paper-description">
                <h3 class=tab4> Combating Catastrophic Forgetting without the Model </h3>
                <p>Catastrophic forgetting is the biggest bottleneck in online deep learning, and is critical to 
                lifelong learning in robots. I initiated a novel idea of using adversarial examples, a flaw of 
                neural networks, to fix catastrophic forgetting, another flaw of neural networks. I introduced 
                a new way of combating catastrophic forgetting in an online learning setting by optimizing input 
                images in an adversarial way without requiring the need for a specific type of architecture or 
                training loss function. We demonstrated that adversarial perturbations to the data is 
                capable of combating catastrophic forgetting.</p>
                <a href="assets/papers/2020AISTATS_combating_catastrophic_forgetting_without_the_model.pdf" class=tab1>PDF</a>
            </div> 
        </div>
       
        <div class="researchpaper">
            <div class="paper-image">
                <img src="assets/pictures/paper2.png" class="paper_pic">
            </div>
            <div class="paper-description">
                <h3 class=tab4> DeepBase: Deep Inspection of Neural Networks</h3>
                <p> We made Deep Neural Inspection (see below) faster and more scalable. We model logic
                with user-provided hypothesis functions that annotate the data with high-level
                labels like POS tags and image captions. Our system then provides sets of 
                neuronal units that show strong statistical correlation with the desired hypothesis.
                The optimizations in this project speed up standard Python implementation by 72X.</p>
                <p> T. Sellam, K. Lin, I. Huang, Y. Chen, M. Yang, C. Vondrick, 
                E. Wu, DeepBase: Deep Inspection of Neural Networks. SIGMOD 2019. </p>
                <a href="assets/papers/2019SIGMOD_DeepBase.pdf" class=tab1>PDF</a>
            </div>
        </div>
 
        <div class="researchpaper">
            <div class="paper-image">
                <img src="assets/pictures/paper1.png" class="paper_pic">
            </div>
            <div class="paper-description">
                <h3 class=tab4> Deep Neural Inspection </h3>
                <p> The explainability of deep learning systems remains a bottleneck. I worked on a system 
                to verify the internal logic of recurrent neural networks. I designed various experiments 
                that sought to validate the identification of important neuron groups. We introduced a 
                novel method called Deep Neural Inspection (DNI) to make sense of internal neuron-level 
                behaviors within recurrent neural networks to dissect and validate their logic for their decisions.</p>
                <p>T. Sellam, K. Lin, I. Huang, E. Wu, C. Vondrick. “I Like the Way You Think!” - Inspecting the Internal Logic of
                Recurrent Neural Networks. SysML Conference 2018.</p>
                <a href="assets/papers/2018SYSML_inspecting_internal_logic_of_RNN.pdf" class=tab1>PDF</a>
            </div> 
        </div>
        
                        
        </div>
 
    </div>
    <script src="js/common.js"></script>
    <script src="js/script_publications.js"></script>

</body>

</html>


